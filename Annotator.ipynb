{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irza/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/irza/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "result  = requests.get(\"https://en.wikipedia.org/wiki/W16_engine\")\n",
    "content = result.content\n",
    "soup = BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete script tags\n",
    "for x in soup.findAll('script'):\n",
    "    x.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A W16 engine is a sixteen cylinder piston internal combustion engine in a four-bank W configuration. The most common layout for W16 engines consists of two 'offset double-row' banks of eight cylinders,[1] coupled to a single crankshaft. Other layouts, though, have been used before as well.Volkswagen Group is the only automotive manufacturer currently producing W16 engines. These engines are most notably used in the Bugatti Veyron and Bugatti Chiron.[2] French car maker Jimenez also used a custom 4.1L W16 made from four Yamaha motorcycle engines in the 1995 Jimenez Novia, a one-off French supercar.[3] The Volkswagen W16 engine was introduced with the mid-engined Bentley Hunaudieres concept car (Bentley Motors Limited has been a Volkswagen Group holding since 1998). This W16 was later used in the Audi Rosemeyer concept car, and in the aforementioned Bugatti Veyron and Chiron.Volkswagen Group's design is a stretched form of its W12 engine, which is itself based on technology from its VR6 engine. In the W16, each side is made up of two VR8 banks and the 'bank' angle is increased to 90 degrees. The narrow angle of each set of cylinders allows just two overhead camshafts to drive each pair of banks, so just four are needed in total. For this reason, the engine is sometimes described as a WR16. The Volkswagen Group W16 engine as configured for the Bugatti Veyron EB16.4 is a 16\\xa0cylinder 64 valve quad-turbocharged engine with four valves per cylinder. The engine is 71 centimetres (28\\xa0in) long and weighs approximately 400 kilograms (882\\xa0lb). Maximum power output is 736 kilowatts (1,001\\xa0PS; 987\\xa0bhp) at 6,000\\xa0revolutions per minute (rpm), with a maximum torque of 1,250 newton metres (922\\xa0lbf⋅ft) (127.5 kgf·m) from 2,200 to 5,500\\xa0rpm.[4] Some automotive press outlets have also reported that the W16 engine design has been considered for use in other Volkswagen Group products - specifically a Bentley.[5] Cylinder firing order on W-16 is as follows: 1-14-9-4-7-12-15-6-13-8-3-16-11-2-5-10.The 4.1L W16 used in the one-off 1995 Jimenez Novia had a very different design than the Volkswagen designed W16. The engine was made by combining four Yamaha FZR1000 1.0 liter 4 cylinder motorcycle engines and has 4 rows of cylinders with 4 cylinders in each row. It has a total of 80 valves (5 valves per cylinder), and it uses two crankshafts, unlike the Volkswagen designed W16.[6] The engine reportedly produces 417.6 kW (567 PS, 560 bhp) at 10,000 RPM and 432 nm (318.6 lb ft of torque).[3][7]\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all paragraph element\n",
    "\n",
    "p_el = soup.find_all('p')\n",
    "\n",
    "all_text=\"\"\n",
    "\n",
    "for x in p_el:    \n",
    "    all_text=all_text+x.get_text()\n",
    "\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize text\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "token = nltk.word_tokenize(all_text)\n",
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prv = nltk.word_tokenize(all_text)\n",
    "prv.pop()\n",
    "prv.insert(0,'')\n",
    "len(prv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxt = nltk.word_tokenize(all_text)\n",
    "nxt.pop(0)\n",
    "nxt.append('')\n",
    "len(nxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find all entities \n",
    "import re\n",
    "\n",
    "entities=None\n",
    "\n",
    "for x in p_el:\n",
    "    a_el=x.find_all('a', {'href': re.compile(r'^/wiki/')})\n",
    "    \n",
    "    if len(a_el) > 0:\n",
    "        if entities is None:\n",
    "            entities=a_el\n",
    "        else:            \n",
    "            entities=entities+a_el\n",
    "\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get previous and next token of entity\n",
    "\n",
    "ent_prev=[]\n",
    "ent_next=[]\n",
    "ent=[]\n",
    "\n",
    "def get_token_from_sibling(el,src):    \n",
    "    res=''\n",
    "    \n",
    "    if el is None:                \n",
    "        if src==\"prev\":\n",
    "            res=''\n",
    "        elif src==\"next\":\n",
    "            res=''\n",
    "            \n",
    "    elif isinstance(el, bs4.element.Tag):\n",
    "        txt=el.get_text()\n",
    "        tkn=nltk.word_tokenize(txt)\n",
    "\n",
    "        if len(tkn) == 0:            \n",
    "            if src==\"prev\":\n",
    "                #print(t,src,type(el.previous_sibling))\n",
    "                res=get_token_from_sibling(el.previous_sibling,src)\n",
    "            elif src==\"next\":\n",
    "                #print(t,src,type(el.next_sibling))\n",
    "                res=get_token_from_sibling(el.next_sibling,src)\n",
    "                \n",
    "        elif src==\"prev\":\n",
    "            res=tkn.pop()\n",
    "        elif src==\"next\":\n",
    "            res=tkn.pop(0)        \n",
    "            \n",
    "    elif isinstance(el, bs4.element.NavigableString):        \n",
    "        tkn=nltk.word_tokenize(el)\n",
    "        \n",
    "        if len(tkn) == 0:               \n",
    "            if src==\"prev\":\n",
    "                #print(t,src,type(el.previous_sibling))\n",
    "                res=get_token_from_sibling(el.previous_sibling,src)\n",
    "            elif src==\"next\":\n",
    "                #print(t,src,type(el.next_sibling))\n",
    "                res=get_token_from_sibling(el.next_sibling,src)\n",
    "                \n",
    "        elif src==\"prev\":\n",
    "            res=tkn.pop()\n",
    "        elif src==\"next\":\n",
    "            res=tkn.pop(0)\n",
    "    \n",
    "    return res\n",
    "\n",
    "for x in entities:    \n",
    "    ent_tkn=nltk.word_tokenize(x.get_text())\n",
    "    \n",
    "    for idx, t in enumerate(ent_tkn):    \n",
    "        ent.append(t)\n",
    "        \n",
    "        if ((idx+1)==len(ent_tkn)) & (idx==0): \n",
    "            ent_prev.append(get_token_from_sibling(x.previous_sibling,\"prev\"))\n",
    "            ent_next.append(get_token_from_sibling(x.next_sibling,\"next\"))\n",
    "        \n",
    "        elif idx==0: \n",
    "            ent_prev.append(get_token_from_sibling(x.previous_sibling,\"prev\"))\n",
    "            ent_next.append(ent_tkn[idx+1])\n",
    "                \n",
    "        elif (idx+1)==len(ent_tkn): \n",
    "            ent_prev.append(ent_tkn[idx-1])\n",
    "            ent_next.append(get_token_from_sibling(x.next_sibling,\"next\"))\n",
    "        \n",
    "        else:\n",
    "            ent_prev.append(ent_tkn[idx-1])\n",
    "            ent_next.append(ent_tkn[idx+1])\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "77\n",
      "77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ent_prev))\n",
    "print(len(ent_next))\n",
    "print(len(ent))\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as text file\n",
    "\n",
    "with open(\"Output.txt\", \"w\") as text_file:    \n",
    "    for idxt, t in enumerate(token):\n",
    "        label=\"O\"\n",
    "        eq_ent=\"\"\n",
    "        eq_ent_prev=\"\"\n",
    "        eq_ent_next=\"\"\n",
    "        connector=\"\"\n",
    "        \n",
    "        for idxet, et in enumerate(ent):\n",
    "            if t == et:\n",
    "                if (prv[idxt]==ent_prev[idxet]) & (nxt[idxt]==ent_next[idxet]):\n",
    "                    label=\"I\"\n",
    "                    eq_ent=et\n",
    "                    eq_ent_prev=ent_prev[idxet]\n",
    "                    eq_ent_next=ent_next[idxet]\n",
    "                    connector=' === '\n",
    "        \n",
    "        text_file.write(t + ' ' + label + connector + eq_ent_prev + \" \" + eq_ent + \" \" + eq_ent_next + \" \" '\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"label.txt\", \"w\") as text_file:    \n",
    "    for idxet, et in enumerate(ent):\n",
    "        text_file.write(ent_prev[idxet] + ' ' + et + ' ' + ent_next[idxet] + '\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"token.txt\", \"w\") as text_file:    \n",
    "    for idxt, t in enumerate(token):\n",
    "        text_file.write(prv[idxt] + ' ' + t + ' ' + nxt[idxt] + '\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(ent[887])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " for idxt, t in enumerate(token):\n",
    "        label=\"O\"\n",
    "        eq_ent=\"\"\n",
    "        eq_ent_prev=\"\"\n",
    "        eq_ent_next=\"\"\n",
    "        eq_idxet=0\n",
    "    \n",
    "        for idxet, et in enumerate(ent):\n",
    "            if t == et:\n",
    "                if (prv[idxt]==ent_prev[idxet]) & (nxt[idxt]==ent_next[idxet]):\n",
    "                    label=\"I\"\n",
    "                    eq_ent=et\n",
    "                    eq_ent_prev=ent_prev[idxet]\n",
    "                    eq_ent_next=ent_next[idxet]\n",
    "                    eq_idxet=idxet\n",
    "        \n",
    "        print(t + ' ' + label + ' : ' + eq_ent_prev + \" \" + eq_ent + \" \" + eq_ent_next + \" \" + str(eq_idxet) + '\\n')                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
